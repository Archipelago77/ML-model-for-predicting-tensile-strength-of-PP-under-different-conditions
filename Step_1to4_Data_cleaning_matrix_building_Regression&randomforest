# Step 1 & 2: Data cleaning and build model input data matrix
import pandas as pd
from sklearn.model_selection import train_test_split

# 1. Load data
df = pd.read_excel("507 final project data-2.xlsx")

# (optional) strip whitespace from column names just in case
df.columns = df.columns.str.strip()

# 2. Keep only rows that have tensile strength, cycles, and polymer_grade
tensile_df = df.dropna(subset=["tensile_strength_MPa", "recycle_cycles", "polymer_grade"])

# 3. Select feature columns

numeric_features = [
    "recycle_cycles",
    "wt_PP",
    "wt_HDPE",
    "wt_ABS",
    "wt_PC",
    "wt_PET",
    "wt_PLA",
    "wt_PS",
    "wt_talc",
    "wt_glass",
    "wt_CaCO3",
    "wt_EPDM",
    "wt_EPR",
    "wt_other",
]

categorical_features = [
    "polymer_grade",
    "processing_method",
    # you can uncomment this if you want to include paper-level differences
    # "source_id",
]

# 5. Build a dataframe with just the features we need
features_df = tensile_df[numeric_features + categorical_features].copy()

# Ensure all numeric features are numeric (sometimes Excel imports blanks as objects)
features_df[numeric_features] = features_df[numeric_features].apply(pd.to_numeric, errors="coerce")

# 6. One-hot encode categorical features
features_encoded = pd.get_dummies(
    features_df,
    columns=categorical_features,
    drop_first=True  # avoid dummy-variable trap
)

# 7. Define X (features) and y (target)
X = features_encoded
y = tensile_df["tensile_strength_MPa"].astype(float)

# 8. Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42
)
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("Number of samples used:", len(y))
print("Number of features used:", X.shape[1])

# 9. Export model-ready matrix to Excel for checking (manual inspection)

#output_df = X.copy()
#output_df["tensile_strength_MPa"] = y.values  # add target column

#output_df.to_excel(
#    "model_ready_matrix.xlsx",
#    index=False)
#print("Saved model-ready matrix to model_ready_matrix.xlsx")

# Step 3: Fit linear regression model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

linreg = LinearRegression()
linreg.fit(X_train, y_train)

y_pred_lr = linreg.predict(X_test)

print("Linear Regression Results")
print("MAE :", mean_absolute_error(y_test, y_pred_lr))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lr)))
print("R²  :", r2_score(y_test, y_pred_lr))

# Step 4: Fit random forest model
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(
    n_estimators=200,
    random_state=42
)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("Random Forest Results")
print("MAE :", mean_absolute_error(y_test, y_pred_rf))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))
print("R²  :", r2_score(y_test, y_pred_rf))

# feature importance from random forest
importances = pd.Series(rf.feature_importances_, index=X_train.columns)
print(importances.sort_values(ascending=False).head(15))

